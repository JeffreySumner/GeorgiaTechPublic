---
title: "Data Visualization 6242: Diabetes Risk Assessment Project"
output: github_document
---

## Disclaimer

The goal of this project was to analyze the BRFSS data to raise awareness to risk factors that increase the likelihood of an individual having diabetes. We are NOT medical professionals and in no way claim to be. Any models and interpretations are our own and medical advice should be sought from a medical professional. Our goal is to merely raise awareness of potential diabetes risk factors. If you believe that there is something medically wrong with you, please contact a healthcare provider.

## Github File Structure

```{r setup, echo=FALSE,message=FALSE,warning=FALSE}
# setwd("submission")
library(tidyverse)
library(data.tree)
```

If you plan to use this repository ensure that you have the following directories stored in the same directory as your .Rproj file or please set your working directory to the submission sub-directory. These directories are required to ensure each script runs. Make sure to include each of the .csv and/or .rds data files.

```{r, echo = FALSE}
paths = unique(c(list.dirs(full.names = T),list.files(full.names = T,recursive = TRUE)))
library(data.tree)
library(plyr)

x <- lapply(strsplit(paths, "/"), function(z) as.data.frame(t(z)))
x <- rbind.fill(x)
x$pathString <- apply(x, 1, function(x) paste(trimws(na.omit(x)), collapse="/"))
(mytree <- data.tree::as.Node(x))

```

## Data Gathering & Cleaning

The data was pulled from the CDC BRFSS website. You can find the information about the survey, data and questionnaires at the following url: <https://www.cdc.gov/brfss/index.html>

For our project we pulled the 2022 dataset and utilized the 2022 BRFSS Codebook to correctly label stored survey responses and enrich variable meaningfulness. The 2022 BRFSS data and 2022 BRFSS Codebook can be downloaded from the following link: <https://www.cdc.gov/brfss/annual_data/annual_2022.html>

The variable list will also need to be downloaded or use the file within the `/data` directory:

<https://data.cdc.gov/Behavioral-Risk-Factors/Behavioral-Risk-Factor-Surveillance-System-BRFSS-H/iuq5-y9ct>

Below are a few examples of our data gathering and cleaning process.

### Loading Packages

Most scripts will have packages listed at the top and should install or load depending on your situation. If has to be installed, you will need to run the line once more when the install completes in order to load the package. Refer to the `scripts/helpers/required_packages.R` if there are any concerns.

```{r, warning=FALSE, message=FALSE,eval=TRUE}
if (!require('devtools')) install.packages('devtools')
if (!require('tidyverse')) install.packages('tidyverse')
if (!require('tidymodels')) install.packages('tidymodels')
if (!require('tictoc')) install.packages('tictoc')
if (!require('glue')) install.packages('glue')
if (!require('httr')) install.packages('httr')
if (!require('rvest')) install.packages('rvest')
if (!require('here')) install.packages('here')
if (!require('ggmap')) install.packages('ggmap')
if (!require('glmnet')) install.packages('glmnet')
if (!require('vip')) install.packages('vip')
if (!require('caret')) install.packages('caret')
if (!require('xgboost')) install.packages('xgboost')
if (!require('ggcorrplot')) install.packages('ggcorrplot')
if (!require('zoo')) install.packages('zoo')
if (!require('lubridate')) install.packages('lubridate')
if (!require('ggthemes')) install.packages('ggthemes')
if (!require('forcats')) install.packages('forcats')
if(!require('bookdown')) install.packages('bookdown')
if(!require('kableExtra')) install.packages('kableExtra')
if(!require('scales')) install.packages('scales')
if(!require('stringr')) install.packages('stringr')
```

### Pull BRFSS Data

If you choose to not manually download the data file listed above, you can use the `scripts/pull_data/gather_brfss.R` in order to pull the data. Below is a sample function that is contained in the script as well as a simple use-case.

```{r, warning=FALSE, message=FALSE,eval=FALSE}
# This can be a single integer or vector of integers
selected_years <- 2022

# this will download the XPT dataset
download_brfss_xpt <- function(year){
  print(year)
  # brfss survey data
  url <- glue::glue("https://www.cdc.gov/brfss/annual_data/{year}/files/LLCP{year}XPT.ZIP")
  storage_location <- glue::glue("data/LLCP{year}XPT.ZIP")
  download.file(url, storage_location, mode="wb")
  unzip(storage_location, exdir = "data/")
}

# Run the function to pull the XPT file
download_brfss_xpt(year = selected_years)

# Turn the XPT file into CSV
convert_xpt_to_csv <- function(year){
  print(year)
  temp_data <- haven::read_xpt(glue::glue("data/LLCP{year}.XPT"))
  readr::write_csv(temp_data, glue::glue("data/SurveyData{year}.csv"))
}

selected_years <- 2022

convert_xpt_to_csv(year = selected_years)
```

The above code will pull the XPT file and convert it to a csv labeled SurveyData{Year}.csv. This survey dataset will be used later to create a sanitized dataset for analysis.

### Clean variable names

Assuming the link to the codebook was followed and downloaded, extract and place the `codebook22_llcp-v2-508.HTML` file in the `/data` directory. With that HTML we will extract the required variable information that is not listed within the downloaded variable names list from the CDC website. For whatever reason there are fields missing between the two. Running the `/scripts/clean_variable_names_html.R` code will create a comprehensive list of fields and their respective values for use within our application.

### Clean BRFSS

With the variable names cleaned up and the survey data ready, we should be able to apply the code within the `/scripts/clean_brfss_2022.R` script. This script reads in the survey data and cleaned up field list to select only columns that are necessary for analysis. This list was curated after extensive research.

## Model & Visualization

This `/model` directory contains 1 script:

1.  create_models.R

Within this script we build and store baseline models and enhanced models. In addition, we will visualize variable importance plots as well as confusion matrices that assist in evaluating model performance.

### Model Building

We will not cover the models in detail but the general concept here is to read in the data created in the previous steps then perform various modeling techniques ranging from LASSO regression, Logistic Regression, and Decision Trees. Please see the tidymodels documentation to find out more about our approach and see examples. You can find this documentation at <https://www.tidymodels.org/>

## Shiny Application

We have an additional script called `app.R` located in the submission directory. This script contains a modularized shinydashboard application that incorporate the models created from our `create_models.R` script. The `app_data` directory contains important variable information that our application uses to correctly display survey questions that have been modified to fit the needs of our tool.

The `/www` directory contains styling information for our application to make it look more stylish.

The application itself is hosted via <https://shinyapps.io> and can be found at the following url <https://rpy-ai.shinyapps.io/DiabetesAwarenessTool/>.

## Wrap up

Below is the session information that was used to create this report. The packages and their versions are listed. R 4.3.1 is required.

```{r}

sessionInfo()
```
